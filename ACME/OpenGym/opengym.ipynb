{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ1tKnrK4TcN"
   },
   "source": [
    "\n",
    "## Volume 2: OpenGym\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qbA8CjB3_IL"
   },
   "source": [
    "<Name\\>\n",
    "<Class\\>\n",
    "<Date\\>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUZ1Wq-8NwSn"
   },
   "source": [
    "**Note:** Some IPython notebook platforms (such as Google Colab) do not currently support rendering OpenAI environments. In order to properly render the OpenGym environments in this lab, you may need to run the Jupyter Notebook locally (for example, run it in VSCode or from the command line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "XqeTGS1PNvZ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /Users/raul/opt/anaconda3/lib/python3.9/site-packages (0.22.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /Users/raul/opt/anaconda3/lib/python3.9/site-packages (from gym) (4.11.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/raul/opt/anaconda3/lib/python3.9/site-packages (from gym) (1.20.3)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/raul/opt/anaconda3/lib/python3.9/site-packages (from gym) (0.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/raul/opt/anaconda3/lib/python3.9/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/raul/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.10.0->gym) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /Users/raul/opt/anaconda3/lib/python3.9/site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "ZlMKi7Fx35TI"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-rNQLwd429z"
   },
   "source": [
    "**Problem 1**\n",
    "\n",
    "*   Implement `random_blackjack()`.\n",
    "*   Run the game 500 times and output the percentage of games that are wins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "lrhUolvq45vh"
   },
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "def random_blackjack(n):\n",
    "    \"\"\"\n",
    "    Play a random game of Blackjack. Determine the\n",
    "    percentage the player wins out of n times.\n",
    "    Parameters:\n",
    "        n (int): number of iterations\n",
    "    Returns:\n",
    "        percent (float): percentage that the player\n",
    "                         wins\n",
    "    \"\"\"\n",
    "    #hist 세팅하기\n",
    "    hist = []\n",
    "    #루프 0 - n-1\n",
    "    for i in range(n):\n",
    "        #게임만들기\n",
    "        done = False\n",
    "        env = gym.make(\"Blackjack-v1\")\n",
    "        #게임 리셋하기 \n",
    "        observation = env.reset()\n",
    "        #안끝날 동안\n",
    "        while(not done):\n",
    "            obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        #승부결과 적기\n",
    "        hist.append(reward)\n",
    "    \n",
    "    env.close()\n",
    "    #결과 비율\n",
    "    w = hist.count(1)\n",
    "    return w/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "JF-bS3gyIx4k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_blackjack(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfZPCIMC5JmB"
   },
   "source": [
    "**Problem 2**\n",
    "\n",
    "* Implement `blackjack()`.\n",
    "* For `n` = 1, 2, ..., 21, plot the win percentage after 10,000 games of Blackjack.\n",
    "* Identify which value of `n` gives the highest win rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "6Uv7AD8I5LWk"
   },
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "def blackjack(n=11):\n",
    "    \"\"\"\n",
    "    Play blackjack with naive algorithm.\n",
    "    Parameters:\n",
    "        n (int): maximum accepted player hand\n",
    "    Return:\n",
    "        percent (float): percentage of 10000 iterations\n",
    "                         that the player wins\n",
    "    \"\"\"\n",
    "    #create the environment\n",
    "    env = gym.make(\"Blackjack-v1\")\n",
    "    #the number of wins\n",
    "    cout = 0\n",
    "    \n",
    "    #루프 0 - 1000\n",
    "    for i in range(10000):\n",
    "        done = False\n",
    "        #initializae the card number\n",
    "        obs = env.reset()\n",
    "        \n",
    "        #get new cards till enough cards\n",
    "        while (obs[0] <= n):\n",
    "            #keep playing\n",
    "            obs, reward, done, info = env.step(1)\n",
    "            #if you actually know if you won or not\n",
    "            if done is True:\n",
    "                if reward == 1:\n",
    "                    cout += 1\n",
    "                break\n",
    "        # you have enough cards but still you didn't win or not\n",
    "        if done is False:\n",
    "            obs, reward, done, info = env.step(0)\n",
    "            if reward == 1:\n",
    "                cout += 1\n",
    "            \n",
    "    env.close()\n",
    "    return cout/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "miBtqMaVIjFJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6822b8700>]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = [blackjack(i) for i in range(1,22)]\n",
    "x = np.linspace(1,22,21)\n",
    "plt.plot(x,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4286\n"
     ]
    }
   ],
   "source": [
    "print(max(num))\n",
    "#around when i is 12 or 13ish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lY8vR6Ygxxk-"
   },
   "source": [
    "*Identify which value(s) give the highest winrate here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9xB1KaZ5OJ3"
   },
   "source": [
    "**Problem 3**\n",
    "\n",
    "* Implement `cartpole()`.\n",
    "* Render the game and run your function once.\n",
    "* Run Cartpole 100 times (without rendering) and print out the average number of steps before it terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "AGEUkBOx5Qbk"
   },
   "outputs": [],
   "source": [
    "# Problem 3\n",
    "def cartpole(render=False):\n",
    "    \"\"\"\n",
    "    Solve CartPole-v0 by checking the velocity\n",
    "    of the tip of the pole.\n",
    "    Parameters: \n",
    "        render (bool): If True, render environment at each step\n",
    "    Return:\n",
    "        iterations (integer): number of steps or iterations\n",
    "                              to solve the environment\n",
    "    \"\"\"\n",
    "    #create environment\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation = env.reset()\n",
    "    #setting count and done\n",
    "    cout = 0\n",
    "    done = False\n",
    "    #while the game is not done\n",
    "    while(not done):\n",
    "        #if the velocity is negative\n",
    "        if observation[3] < 0:\n",
    "            observation, reward, done, info = env.step(0)\n",
    "        #if the velocity is postiive\n",
    "        else:\n",
    "            observation, reward, done, info = env.step(1)\n",
    "        #add the steps\n",
    "        cout += 1\n",
    "            \n",
    "    env.close()\n",
    "    return cout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "78iSdRs6wZKb"
   },
   "outputs": [],
   "source": [
    "# Render the game and run once hered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "EaNbYfsuIhxN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196.25\n"
     ]
    }
   ],
   "source": [
    "# Run the game here and print average steps to termination\n",
    "nums = sum([cartpole() for i in range(100)])\n",
    "print(nums/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPFFk0nX5U_b"
   },
   "source": [
    "**Problem 4**\n",
    "\n",
    "* Implement `car()`.\n",
    "* Render the game and run your function once.\n",
    "* Run MountainCar 100 times (without rendering) and print out the average number of steps before it terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "Lqq3Q6EO5Wgq"
   },
   "outputs": [],
   "source": [
    "# Problem 4\n",
    "def car(render=False):\n",
    "    \"\"\"\n",
    "    Solve MountainCar-v0 by checking the position\n",
    "    of the car.\n",
    "    Parameters: \n",
    "        render (bool): If True, render environment at each step\n",
    "    Return:\n",
    "        iterations (integer): number of steps or iterations\n",
    "                              to solve the environment\n",
    "    \"\"\"\n",
    "    env = gym.make(\"MountainCar-v0\")\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    cout = 0\n",
    "    \n",
    "    while(not done):\n",
    "        if(observation[1] >0):\n",
    "            observation, reward, done, info = env.step(2)\n",
    "        elif(observation[1]<0):\n",
    "            observation, reward, done, info = env.step(0)\n",
    "        else:\n",
    "            observation, reward, done, info = env.step(1)\n",
    "        cout += 1\n",
    "            \n",
    "    env.close()\n",
    "    return cout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "4_kSEBYdwgnc"
   },
   "outputs": [],
   "source": [
    "# Render the game here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "fUsBDn6KIgw5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.79\n"
     ]
    }
   ],
   "source": [
    "# Run the game here and print average steps to termination\n",
    "nums = sum([car() for i in range(100)])\n",
    "print(nums/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5tSd-zE4sHZ"
   },
   "source": [
    "**Helper Function for Problem 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "zNNc3x9x09Zr"
   },
   "outputs": [],
   "source": [
    "def find_qvalues(env,alpha=.1,gamma=.6,epsilon=.1):\n",
    "    \"\"\"\n",
    "    Use the Q-learning algorithm to find qvalues.\n",
    "    Parameters:\n",
    "        env (str): environment name\n",
    "        alpha (float): learning rate\n",
    "        gamma (float): discount factor\n",
    "        epsilon (float): maximum value\n",
    "    Returns:\n",
    "        q_table (ndarray nxm)\n",
    "    \"\"\"\n",
    "    # Make environment\n",
    "    env = gym.make(env)\n",
    "    # Make Q-table\n",
    "    q_table = np.zeros((env.observation_space.n,env.action_space.n))\n",
    "\n",
    "    # Train\n",
    "    for i in range(1,100001):\n",
    "        # Reset state\n",
    "        state = env.reset()\n",
    "\n",
    "        epochs, penalties, reward, = 0,0,0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Accept based on alpha\n",
    "            if random.uniform(0,1) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            # Take action\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Calculate new qvalue\n",
    "            old_value = q_table[state,action]\n",
    "            next_max = np.max(q_table[next_state])\n",
    "\n",
    "            new_value = (1-alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            q_table[state, action] = new_value\n",
    "\n",
    "            # Check if penalty is made\n",
    "            if reward == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            # Get next observation\n",
    "            state = next_state\n",
    "            epochs += 1\n",
    "\n",
    "        # Print episode number\n",
    "        if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Episode: {i}\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    return q_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZODhO4AS5YQq"
   },
   "source": [
    "**Problem 5**\n",
    "\n",
    "* Render the \"`Taxi-v3`\" environment, act randomly until it terminates, and calculate the total reward\n",
    "* Render the \"`Taxi-v3`\" environment, use the Q-table to act optimally until it terminates, and calculate the total reward\n",
    "* Implement `taxi()`, then use it to print the average total reward for each algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "e3i-LEnYKHyz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-848\n"
     ]
    }
   ],
   "source": [
    "# Random actions Taxi game\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "#restart the game\n",
    "observation = env.reset()\n",
    "#initialization\n",
    "done = False\n",
    "re = 0\n",
    "#while the game is not done\n",
    "while (not done):\n",
    "    observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    re += reward\n",
    "#end the game\n",
    "env.close()\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "0ejXeML7KJSJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Q-table actions Taxi game\n",
    "q_tab = find_qvalues(\"Taxi-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "APK2iYQV5aR4"
   },
   "outputs": [],
   "source": [
    "def taxi(q_table):\n",
    "    \"\"\"\n",
    "    Compare naive and q-learning algorithms.\n",
    "    Parameters:\n",
    "        q_table (ndarray nxm): table of qvalues\n",
    "    Returns:\n",
    "        naive (float): mean reward of naive algorithm\n",
    "                       of 10000 runs\n",
    "        q_reward (float): mean reward of Q-learning algorithm\n",
    "                          of 10000 runs\n",
    "    \"\"\"\n",
    "    #naive algorithm\n",
    "    lis_ran = []\n",
    "    for i in range(10000):\n",
    "        env = gym.make(\"Taxi-v3\")\n",
    "        done = False\n",
    "        re_ran = 0\n",
    "        observation = env.reset()\n",
    "        \n",
    "        while (not done):\n",
    "            observation, reward, done, info = env.step(env.action_space.sample())\n",
    "            re_ran += reward\n",
    "        lis_ran.append(re_ran)\n",
    "        env.close()\n",
    "        \n",
    "    #not random algorithm\n",
    "    lis_not = []\n",
    "    for i in range(10000):\n",
    "        env = gym.make(\"Taxi-v3\")\n",
    "        done = False\n",
    "        re_not = 0\n",
    "        observation = env.reset()\n",
    "        \n",
    "        while (not done):\n",
    "            observation, reward, done, info = env.step(np.argmax(q_table[observation, :]))\n",
    "            re_not += reward\n",
    "        lis_not.append(re_not)\n",
    "        env.close()\n",
    "    \n",
    "    \n",
    "    return sum(lis_ran)/10000, sum(lis_not)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "PhS7JR1JKOQu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-771.9607, 7.9131)\n"
     ]
    }
   ],
   "source": [
    "# Print the average rewards of the Taxi game for both algorithms run 10,000 times\n",
    "print(taxi(q_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "opengym.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
